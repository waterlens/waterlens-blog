= xref:.[知识点回顾]
:showtitle:
:lang: zh-hans
:stem: latexmath

最近在找工作，因此回顾一下自己简历上可能相关的知识点。

== Algebraic Data Type 代数数据类型

由其他数据类型组合而成的数据类型。
通常于函数式编程语言与类型论的语境下被提及，但近些年来，
这个概念也逐渐被（部分地）引入到通用编程语言的设计中。
通常情况下，指代的是以下两种类型：

- 和类型：体现为元组或记录等（也就是命名元组）
- 积类型：体现为联合或者枚举等

一个直观的解释 (from ice1000)：A 有 6 种可能，B 有 7 种可能，
那么 A 和 B 的和类型组合有 6 + 7 = 13 种可能，
而 A 和 B 的积类型组合有 6 * 7 = 42 种可能。

*如何表示存在递归的 ADT?*

- 形式化上：使用 stem:[\mu] 类型算子
  例子：自然数类型可以表示为 stem:[\mu X. Z + S \times X]
- 实践上：主要问题是形成了环，所以不再能假设类型是树状数据结构表示的（能简单地递归比较）。
  但好在形成环都是因为使用了对另一类型或自己的引用，这些引用可以要么用名字表示（当然这样做的话，类型检查、推导时候得使用一个类型环境），
  要么就使用一个可变的引用，对类型进行 hash-consing，然后可以简单地使用引用相等性比较。
- 进阶一点：如果我们的类型系统被拓展到了依值类型 (Dependent Type)，那么对类型等价的判断就变得非常重要了。有一些相关的技术，
  例如 De Bruijn 索引，NbE (Normalization by Evaluation)，HOAS (Higher-Order Abstract Syntax)，等。关于后两者，
  有一个有趣的参考：
  https://julesjacobs.com/notes/smartconstr/smartconstr.pdf[Smart Constructors].


== 高阶函数
可以作为一流值 (first-class values) 而出现在参数、返回值等位置的函数。

不完全等同但相关的实现方式：

*函数闭包*：Scheme 引入，由环境和代码两个部分组成，所有代码部分引用的“自由变量”都从对应的环境中获取。

相关概念：

- 扁平闭包：所有被引用的自由变量都直接存储在当前闭包中。优点是更加快速，缺点是占用更多内存。
- 链式闭包：如果存在嵌套的闭包（例如，闭包 A 包含闭包 B 和 C，而 B 和 C 都引用了自由变量 x），
          那么可以考虑将 x 存储在闭包 A 中，而不是闭包 B 和 C 中，在 B 和 C 中我们只保留一个指向闭包 A 的指针。
          优点是节省内存，缺点是无法快速访问 x，需要沿着闭包链向上查找；另外，指向上层闭包的指针也可能导致意外地延长
          上层闭包包含对象的生命周期，导致内存泄露。
- 互递归函数形成的互递归闭包：可以被合并成同一个闭包。好处是没有环，不会干扰引用技术类垃圾回收器的工作。

相关技术在 Compiling with Continuations 中被提及。

在某些 OOP 导向的语言里（如 C++），由于环境、代码等实现细节可以被对应到对象中的字段、为对象重载的调用操作符等，
因此可以比较方便地模拟闭包。默认情况下，这种方式是单态化的，也就是说重载的调用操作符是一个直接调用而非间接调用；
如果需要实现多态化，则需要使用虚函数。这里，实现间存在一种隔阂：C++ 支持单态化（在调用点即确定闭包所调用的函数），
但一旦出现多态的情况（特定调用点可能有多个可能的闭包），使用虚函数就极大增加了开销（并非直接的函数指针，而是虚函数表）；
MLton 不会诉诸于虚函数、函数指针，而是借助了以下描述的 *去函数化* 技术，但它却不能实现足够的单态化。
在 https://dl.acm.org/doi/pdf/10.1145/3591260[Beer Defunctionalization through Lambda Set Specialization] 中，
作者描述了这种隔阂。

*去函数化*：这种方法首先由
https://surface.syr.edu/cgi/viewcontent.cgi?article=1012&context=lcsmith_other[Definitional interpreters for higher-order programming languages]
提出，其核心思想是，使用宿主语言里的数据结构类型去表示闭包中的环境（用“变体”携带的 tag 具体区分所用的闭包类型），
并使用一个单独的 `apply` 函数去根据 tag 提取出环境中的值，然后调用对应的代码。
在这种方式下，所有的闭包创建都变成了对数据构造（包含类型变量），并且所有的闭包调用都变成了使用闭包为参数，调用
`apply` 函数。这种方式在之后也得到了长久的发展（根据数据流分析和类型分析的优化，分离 `apply` 函数等），
但概念上的普及反而不如上一种方法。

== 链接器

=== 静态链接：

1. *符号解析*：将符号（全局变量，函数等）引用与唯一的符号定义关联起来。
2. *重定位*：
+
--
_编译器和汇编器生成的代码和数据段假设地址从 0 开始。_ 
链接器通过将符号和一个地址关联起来来，并修改所有对这个新地址的引用从而完成重定位。
--

=== 对象文件

1. 可重定位对象文件
2. 可执行对象文件
3. 共享对象文件：可以被动态链接的特殊可重定位文件

=== 符号和符号表

1. 全局符号
2. 外部符号
3. 局部符号：（static C 函数和 static 变量）

*COMMON 段和 .bss 段的区别*：
当多个全局变量被定义但未被初始化时，编译器不认为为冲突并且链接器可以选择任意可用定义中的一个，+
此时将这些变量放入 COMMON 段允许惰性选择定义。

=== 符号解析

从符号表

陷阱：如果一个 archive 文件被放置于实际使用其中符号的另一个对象文件之前，那么可能因为链接器+
提前跳过 archive 中的符号而导致错误。

=== 重定位

1. 重定位段、符号定义
2. 重定位段内的符号引用

==== 重定位条目

例如，对于 `elf` 文件，在 `+.rel.text+` 和 `+.rel.data+` 段中，
分别包含了 `+.text+` 和 `+.data+` 段的重定位条目。

x86-64 架构上的两种常见重定位类型：

1. `R_X86_64_32`：重新定位使用对 32 位绝对地址的引用。
通过绝对寻址，CPU 直接使用指令中编码的 32 位值作为有效地址，无需进一步修改。

2. `R_X86_64_PC32`：使用一个 32 位 PC-relative 偏移量来重新定位引用。

==== 重定位算法

[source]
----
foreach section s {
  foreach relocation entry r {
    refptr = s + r.offset; /* ptr to reference to be relocated */
    /* Relocate a PC-relative reference */
    if (r.type == R_X86_64_PC32) {
      refaddr = ADDR(s) + r.offset; /* ref’s run-time address */
      *refptr = (unsigned) (ADDR(r.symbol) + r.addend - refaddr);
    }
    /* Relocate an absolute reference */
    if (r.type == R_X86_64_32) {
      *refptr = (unsigned) (ADDR(r.symbol) + r.addend);
    }
  }
}
----

=== 动态链接

在加载或者运行时，动态加载一个共享库并进行链接。

当加载器加载一个使用了共享库的程序时，需要执行以下步骤：

1. 重定位共享库
2. 重定位对共享库中符号的引用


==== PIC（地址无关代码）

允许代码被加载、执行而无需任何重定位。

*PIC 数据引用*：通过 GOT（Global Offset Table）来实现。+
对于每个全局变量使用一个 8 字节条目，被使用全局变量的代码所引用；+
并生成对应的重定位条目，使得在加载时，GOT 里的条目在重定位后包含了对象的绝对地址。+
每个对象都有其自己的独立 GOT。

*PIC 函数引用和延迟绑定*：通过 PLT（Procedure Linkage Table）来实现。

1. 程序不是直接调用 `addvec`，而是调用 `PLT[2]`，这是 `addvec` 的 PLT 入口。
2. 第一个 PLT 指令通过 `GOT[4]` 进行间接跳转。由于每个 GOT 条目最初指向其对应的 PLT 入口中的第二条指令，因此这个间接跳转只是将控制权转移到 `PLT[2]` 中的下一条指令。
3. 在将 `addvec` 的 ID（0x1）压入栈之后，`PLT[2]` 跳转到 `PLT[0]`。
4. `PLT[0]` 通过 `GOT[1]` 间接压入一个参数给动态链接器，然后通过 `GOT[2]` 间接跳转到动态链接器。+
动态链接器使用这两个栈条目来确定 `addvec` 的运行时地址，将 `GOT[4]` 替换为这个地址，然后将控制权传递给 `addvec`。

相比于全局变量，额外的步骤主要是为了实现惰性加载。

*共享库需要 PIC 的核心原因*：+ 
尽管加载器可以运行时候加载并修补代码中的偏移量，但这也导致共享库无法被共享：
每个进程所需的代码中的偏移量都不同。因此，通过一层间接，我们允许共享库的
代码段保持只读状态，而只需要修补数据段（而这本来就是共享库应有的机制）。

== 优化技术


=== 稀疏简单常量传播

在 SSA 式 IR 上进行，为每个名字关联一个格元素，stem:[\{\top,~\bot,~C\}]，
其中 stem:[\top] 表示未知；stem:[\bot] 表示可能为任意值。

1. 首先根据所有名字关联的操作的实际内容更新其格元素；常量或 stem:[\top] 元素；
   将不为顶元素的名字加入初始工作列表
2. 取出已知其格元素的名字；更新所有使用它的指令的结果名字的格元素，如果结果名字的格元素不为 stem:[\bot]（不可知）。

关于终止性：每个名字最多改变两次格元素，故每个名字最多出现在工作列表中两次。

初始化为 stem:[\top] 为乐观分析；和悲观分析的不同在于允许在环中传递值。
有用的例子：

[source]
----
  x0 = 42
  x1 = ???
  goto L1(p0)
L1(p0)
  x1 = p0 + 0
  if x1 goto L1(x1) else goto L2(x1)
L2(p1)
  ...
----


=== 稀疏条件常量传播

关联：抽象解释和符号执行的不同：
符号执行不关心探索所有可能的执行路径，而只关心探索那些可能的执行路径。
符号执行形成执行树。

结合稀疏简单常量传播和不可达分析；

1. 关联每个名字到 stem:[\top]，标记所有控制流边为未执行。
2. 取出一条控制边，如果已执行，则跳过；否则标记为执行并更新目标块里的 phi 节点的操作数。
   如果目标块没有其他执行的边，则更新目标块里的指令，
   然后根据控制指令的类型和它的条件格元素加入新的边。
3. 取出一条数据边，先看目标是否可达，如果不可达，则跳过；否则更新（或合并）目标指令的操作数。

比较：
当遇到条件时，相比于稀疏简单常量传播，还会处理不可达性。
不可达的块中的抽象值不会流入到其他块中。SCCP 只在数据流上进行格元素合并，而不在控制流上进行合并。


=== 支配边界的计算

- *Lengauer-Tarjan 算法和 Semi-NCA 算法*：

动机：增量 LT 只能通过修复 IDOM 来修补，因此手动更新困难，往往选择重新计算。

复杂度变化：从 stem:[O(E\alpha(E, V))] 到 stem:[O(V^2)]。

- *Cooper 算法：*
使用数据流分析：

[stem]
++++
\def\sc#1{\dosc#1\csod} \def\dosc#1#2\csod{{\rm #1{\small #2}}}
\newcommand{\dom}{\sc{DOM}}

\dom(n) = \{n\} \cup \left(\ \bigcap_{m \in \text{pred}(n)} \dom(m) \right)
++++

初始值：

[stem]
++++
\def\sc#1{\dosc#1\csod} \def\dosc#1#2\csod{{\rm #1{\small #2}}}
\newcommand{\dom}{\sc{DOM}}\\

\dom(n_{entry}) = \{n_{entry}\}\\

\dom(n) = N, \forall n \neq n_{entry}
++++

*逆后序*：拓扑顺序。确保每个块的前驱都在块之前已经被访问。
*反向 CFG 上的逆后序*：为什么不用后序？循环时不同。
https://eli.thegreenplace.net/2015/directed-graph-traversal-orderings-and-applications-to-data-flow-analysis/[参考]。例子如下：

[source]
----
A - B - D
   | |
    C
----

加速技巧：将 Dom 集表示为树，合并时候使用 2-finger 算法。

*支配边界的定义*：b 的支配边界是集合 Y，其中 Y 中的每个块 b' 的每个前驱都被 b 支配，但 b' 不被 b 支配。

*找支配边界*：所有汇合点都在其前驱的支配边界中，除非其前驱支配该汇合点；因此可以从汇合点开始构造性地产生支配边界集合。

.根据 IDOM 计算 DF 集合的算法
[source]
----
for all nodes, n, in the CFG do DF(n) ← ∅
for all nodes, n, in the CFG do
  if n has multiple predecessors then
    for each CFG predecessor p of n do
      runner ← p
      while runner = IDOM(n) do
        DF(runner) ← DF(runner) ∪ { n }
        runner ← IDOM(runner)
----

集合的迭代支配边界：

[stem]
++++
DF_1(S) = DF(S)\\
DF_{i+1}(S) = DF (S \cup DF_i(S))
++++


=== SSA 构建

最小 SSA 在任何两个不同定义相同原始名称相遇的连接点插入φ函数。

修剪 SSA 在φ函数插入算法中添加了一个存活性测试，以避免添加无效的φ函数。
这种构建必须计算 LIVE OUT 集合，这增加了构建修剪 SSA 的成本。

半修剪 SSA 是在最小 SSA 和修剪 SSA 之间的一种妥协。
在插入φ函数之前，算法会消除任何在块边界处不存活的名称。
这可以缩小名称空间并减少φ函数的数量，而无需计算 LIVEOUT 集合的开销。

*最小 SSA 的构建*：

- Phi 插入算法：找到变量 x 的定义块集 B 加入工作列表；
  从工作列表取出块 b，对于其每个支配边界块 d，如果不包含为 x 的 phi 指令，则插入 phi 指令；
  将 d 加入工作列表。
- 重命名：为基本块内的每个名字的新定义分配一个新名字并压栈；
  重命名所有位于其支配树里的后继基本块；弹出本基本块中的新名字。


=== 死代码消除和不可达代码消除

区别：死代码消除移除可能被执行，但既无副作用而结果又不被使用的代码；
不可达代码消除移除不可能到达的代码。

*死代码消除*：

数据流：类似 Mark-Sweep 算法，从“关键”指令开始，
标记所有依赖的指令。

控制依赖性：
后支配关系：所有从 b 到 exit 的路径都经过 b', 则 b' 后支配 b。
所有后支配边界的块的分支指令都是有用的。

*不可达代码消除*：

没有控制流路径或者条件恒不成立；后者依赖 SCCP 优化。


=== CFG 化简

- 折叠冗余分支（例如跳转到同一目标）
- 移除空基本块
- 合并基本块


=== 值编号

局部的：

- 维护一个指令到输出值的表中
- 当遇到指令时，如果指令已经在映射中，则将这条指令的输出值的所有使用替换为表中的输出值
- 否则，将这条指令到其输出值的映射加入表中

拓展：

- 超局部值编号：拓展基本块：一组块集合 stem:[\{ B_0, B_1, \dots, B_k \}]，
  其中要么 stem:[B_0] 是入口节点，要么 stem:[B_0] 有多个 CFG 前驱，
  而每其他 stem:[B_i] 都只有一个前驱，该前驱在该集合中。

和公共子表达式消除的关系：CSE 不会追踪在有中间复制下的表达式等价性；更聚焦于在全局背景下寻找完全相同的表达式并替换。


=== 冗余优化辨析

公共子表达式消除 (Common Subexpression Elimination)：
查找在给定执行路径上至少执行两次的计算，并消除其中的第二次及后续出现的计算。
这种优化需要数据流分析（Available Expression 分析）来定位冗余计算。

循环不变量代码移动 (Loop Invariant Code Motion)：查找每次循环迭代都会产生相同结果的计算，并将它们移出循环。
虽然可以通过独立的数据流分析来确定这一点，但通常基于使用 Use-Def 链。
这种优化几乎总是能提高性能，通常非常显著，很大程度上是因为它经常发现并移除循环不变量的地址计算，通常还包括那些访问数组元素的计算。

部分冗余消除 (Partial Redundancy Elimination)：
将至少部分冗余的计算（即在流图的某些路径上被计算多次的计算）移动到其最优计算点，并完全消除冗余的计算。
它包括公共子表达式消除、循环不变量代码移动，以及更多内容。

代码提升 (Code Hoisting)：查找在程序中从某一点开始的所有路径上都会执行的计算，并将它们统一为在该点的一个计算。
它需要数据流分析（即一种名称略显滑稽的“非常繁忙的表达式”分析形式），并减少程序所占用的空间，但很少影响其时间性能。


=== 惰性代码移动

增强版 PRE。

*可用表达式分析*：

计算控制流图中的一个节点（基本块）入口处所有可用的表达式。

[stem]
++++
\def\sc#1{\dosc#1\csod}\def\dosc#1#2\csod{{\rm #1{\small #2}}}
\newcommand{\avail}{\sc{AVAIL}\sc{IN}}\\
\newcommand{\deexpr}{\sc{D}\sc{E}\sc{EXPR}}\\
\newcommand{\exprkill}{\sc{EXPR}\sc{KILL}}\\
\avail(n) = \bigcap_{m \in \text{preds}(n)} \left(\deexpr(m) \cup \left(\avail(m) \cap \exprkill(m) \right) \right)
++++

其中初始值为：

[stem]
++++
\def\sc#1{\dosc#1\csod}\def\dosc#1#2\csod{{\rm #1{\small #2}}}
\newcommand{\avail}{\sc{AVAIL}\sc{IN}}\\
\avail(n_{entry}) = \emptyset\\
\avail(n) = \{ \text{all expressions} \}, \forall n \neq n_{entry}
++++

stem:[\def\sc#1{\dosc#1\csod}\def\dosc#1#2\csod{{\rm #1{\small #2}}}\newcommand{\deexpr}{\sc{D}\sc{E}\sc{EXPR}}\deexpr(n)] 是 stem:[n] 中向下暴露的表达式集合。
一个表达式 stem:[e] 属于 stem:[\def\sc#1{\dosc#1\csod}\def\dosc#1#2\csod{{\rm #1{\small #2}}}\newcommand{\deexpr}{\sc{D}\sc{E}\sc{EXPR}}\deexpr(n)]，
当且仅当基本块 stem:[n] 评估 stem:[e]，并且 stem:[e] 的所有操作数在 stem:[e] 在 stem:[n] 中的最后一次评估和 stem:[n] 结束之间都没有被定义。
stem:[\def\sc#1{\dosc#1\csod}\def\dosc#1#2\csod{{\rm #1{\small #2}}}\newcommand{\exprkill}{\sc{EXPR}\sc{KILL}}\exprkill(n)] 包含所有被 stem:[n] 中的定义所杀死的表达式。一个表达式被杀死，当且仅当它的某个或某些操作数在块中被重新定义。

*忙碌表达式分析*：

无论从某一点采取什么路径，表达式都会被评估，则称作该表达式在该点为忙碌的表达式。

*惰性代码移动*：

TODO


=== 生命周期分析

[stem]
++++
\def\sc#1{\dosc#1\csod}\def\dosc#1#2\csod{{\rm #1{\small #2}}}
\newcommand{\liveout}{\sc{LIVE}\sc{OUT}}\\
\newcommand{\uevar}{\sc{UE}\sc{VAR}}\\
\newcommand{\varkill}{\sc{VAR}\sc{KILL}}\\
\liveout(n) = \bigcup_{m \in \text{succs}(n)} \left(\uevar(m) \cup \left(\liveout(m) \cap \varkill(m) \right) \right)
++++

SSA（stem:[\phi] 指令）：

[stem]
++++
\def\sc#1{\dosc#1\csod}\def\dosc#1#2\csod{{\rm #1{\small #2}}}
\newcommand{\liveout}{\sc{LIVE}\sc{OUT}}\\
\newcommand{\livein}{\sc{LIVE}\sc{IN}}\\
\newcommand{\phidefs}{\sc{PHI}\sc{DEFS}}\\
\newcommand{\uevar}{\sc{UE}\sc{VAR}}\\
\newcommand{\phiuses}{\sc{PHI}\sc{USES}}\\
\newcommand{\defs}{\sc{DEFS}}\\
\livein(n) = \phidefs(n) \cup \uevar(n) \cup \left(\liveout(n) \setminus \defs(n) \right) \\
\liveout(n) = \bigcup_{m \in \text{succs}(n)} \left(\livein(m) \setminus \phidefs(m) \right) \cup \phiuses(n)
++++

SSA（块参数）：

[stem]
++++
\def\sc#1{\dosc#1\csod}\def\dosc#1#2\csod{{\rm #1{\small #2}}}
\newcommand{\liveout}{\sc{LIVE}\sc{OUT}}\\
\newcommand{\livein}{\sc{LIVE}\sc{IN}}\\
\newcommand{\uevar}{\sc{UE}\sc{VAR}}\\
\newcommand{\defs}{\sc{DEFS}}\\
\newcommand{\uses}{\sc{USES}}\\
\newcommand{\jumpuses}{\sc{JUMP}\sc{USES}}\\
\newcommand{\bp}{\sc{BLOCK}\sc{PARAMS}}\\
\livein(n) = \bp(n) \cup \uevar(n) \cup \left(\liveout(n) \setminus \defs(n) \right) \\
\liveout(n) = \bigcup_{m \in \text{succs}(n)} \left(\livein(m) \setminus \bp(m) \right) \cup \jumpuses(n)
++++


=== 超级字向量化

搭配循环展开使用。
SLP 向量化通过在直行代码中寻找独立的、同构的指令，并将其替换为向量指令来实现。
由于 SLP 向量化针对的是直行代码，因此它只需要更简单的依赖性分析（与循环向量化所需的更复杂的循环依赖性分析相比）。


=== 杂项

*循环分裂（Loop Unswitching）*：
如果循环体内有一个不会在循环过程中改变的条件判断（即该条件与循环变量无关），
那么可以将这个条件判断“搬”到循环外部，把循环拆分成两个（或多个）没有该条件判断的循环。

*If 转换（If-conversion）*：
If 转换通过将程序转换为无条件执行每个条件分支的两个分支，将控制依赖转换为数据依赖，
并用 select 指令（根据布尔条件选择两个替代值，类似于 C/C++ 中的三元运算符）替换控制流的合并（即 SSA 中的φ节点）。

=== JIT 特定

*栈上替换（On-Stack Replacement）*：
栈上代码替换：一种运行时系统暂停执行，即时编译正在执行的程序，然后使用新编译的代码继续执行的技术。

创建一些 stub：移动、新计算、丢弃某些值。
替换栈帧、切换上下文。


*内联缓存（Inline Cache）*：
查找表缓存指特定于调用点的一种缓存，用于将（对象类型，方法名）映射到实际方法并缓存结果上。

其工作流程如下：调用方法时，查找对应的缓存，如果未命中则回退到标准路径，并缓存结果。

内联缓存是进一步的优化，将查找的结果缓存到调用点处（例如，替换掉原有的调用指令）。
当然，目标方法也需要设置对应的检查以在对象类型不匹配时回退到标准路径。

这种只缓存一个结果的内联缓存被称作单态的；
对应的我们还有多态内联缓存，对应一个调用点具有多种对象类型和方法的情况。
这时生成一个 PIC stub，用一系列条件判断来决定调用哪个方法。
当然，必须要控制 stub 大小以避免起不到加速效果。

*隐藏类（Hidden Class）*：

可以搭配内联缓存使用；替换内联缓存里描述的类型。
描述对象的基本布局等信息。

=== LLVM 中的优化

== 并发

=== 原子原语

*Bakery 锁模拟*：

- 每个线程获取一个“号码”，并等待比自己号码小的线程完成。
- 通过比较号码和线程 ID 确定访问顺序。

[source]
----
bool choosing[N] = {false};
int number[N] = {0};

void enter_critical_section(int i) {
    choosing[i] = true;
    number[i] = max(number[0], number[1], ..., number[N-1]) + 1;
    choosing[i] = false;

    for (int j = 0; j < N; j++) {
        while (choosing[j]) {} // 等待其他线程选号
        while (number[j] != 0 && (number[j] < number[i] || (number[j] == number[i] && j < i))) {
            // 等待优先级更高的线程
        }
    }
}

void leave_critical_section(int i) {
    number[i] = 0;
}
----

== 体系结构

=== 流水线

简单的五级流水线：

1. 取指 (IF)
2. 译码 (ID)
3. 执行 (EX)
4. 访存 (MEM)
5. 写回 (WB)

限制流水线被充分利用的约束：

1. *结构冒险*：两条指令竞争同一个功能单元；可被重复功能单元解决
2. *数据冒险*：指令间的数据依赖：
+
--
* 写后读 (RAW):
+
[source]
----
R1 = R0 + 1
R2 = R1 + 1
----
+
解决办法（部分缓解）：数据前递。

TODO：在经典五级流水线里，前递最多能缓解数据冒险多少个周期？
  
* 读后写 (WAR):
+
[source]
----
R1 = R0 + 1
R0 = R2 + 1
----
+
解决办法：寄存器重命名。

* 写后写 (WAW):
+
[source]
----
R1 = R0 + 1
R2 = R1 - 2
R1 = R0 * 3
----
解决办法：寄存器重命名。

--
3. *控制冒险*：
来自于改变控制流的指令，例如分支或者跳转。
解决办法（部分缓解）：动态分支预测和推测执行。

=== 指令级并行

1. *乱序执行*：
+
--
指令可以以任意顺序进入特定流水线阶段，只受依赖关系和资源的限制（而非指令顺序）。

重排序指令的过程被称作 _指令调度_ 。

- 静态调度：IA-64，似了
- 动态调度：Scoreboarding 算法或 Tomasulo 算法。

*Scoreboarding 算法*：

主要缺点：不仅保留了真依赖，也保留了伪依赖（WAW 和 WAR）。

*Tomasulo 算法*：

改进：加入了寄存器重命名机制。

1. 保留站：缓冲 (buffer) 等待发射的指令的操作数。可以消除从寄存器读的需要并只保留最新的对寄存器的写。
  “使用保留站而不是集中式的寄存器文件，会导致另外两个重要的特性。首先，危险检测和执行控制是分布式的：每个功能单元的保留站中保存的信息决定了该指令何时可以在该单元开始执行。
  其次，结果直接从保留站传递到功能单元，而不是经过寄存器。这种绕过是通过一个公共结果总线实现的，它允许所有等待操作数的功能单元同时加载。
  在可以每个时钟周期发出多条指令并且拥有多个执行单元的流水线中，将需要多个结果总线。”
2. 三阶段：发射（分派），执行（发射），写回。分别代表指令从队列送入保留站、保留站等待指令操作数就绪后将指令送入执行单元、执行单元完成计算后将结果放置于总线上（提供给寄存器堆、保留站、存储缓冲区等）。
3. 在 Tomasulo 算法中，保留站被用作拓展的虚拟寄存器；但存在其他方案，例如重排序缓冲区。
4. “Tomasulo 算法会在源和结果之间引入一个周期的延迟，因为结果与其使用之间的匹配只能在写回阶段结束时进行，而不是像简单流水线那样在执行阶段结束时进行。因此，在动态调度流水线中，产生指令和消费指令之间的有效延迟至少比产生结果的功能单元的延迟多一个周期。”
5. “Tomasulo 算法中的标签指的是将产生结果的缓冲区或执行单元；当一条指令被发往保留站时，寄存器名称会被丢弃。这是 Tomasulo 算法与计分板算法之间的关键区别：在计分板算法中，操作数保留在寄存器中，只有在产生该操作数的指令执行完成，且消费该操作数的指令准备好执行时才会被读取。”

保留站的字段：(Op, Qj, Qk, Vj, Vk, Addr, Busy)：（指令类型，产生操作数 1 的保留站编号，产生操作数 2 的保留站编号，操作数 1 的值，操作数 2 的值，立即数或地址，是否繁忙）

寄存器堆的字段：(Qi)：（产生结果需要存入该寄存器的保留站编号）

通往模拟器的链接：xref:/tomasulo/index.html[Tomasulo's Algorithm Simulator]

--

2. *推测执行*：
+
--
硬件推测执行的三个核心思想：

* 进行动态分支预测选择可能会执行的指令
* 在控制依赖未得到解决时就开始推测执行
* 跨越基本块的动态调度

要将 Tomasulo 算法扩展以支持推测，必须将指令之间结果传递所需的机制，与指令的实际完成分开。
通过这种分离以允许一条指令执行并将结果传递给其他指令，而不允许该指令进行任何无法撤销的更新，直到确定该指令不再具有推测性。

为此，加入一组额外的缓冲区容纳那些执行完成但尚未准备好提交其结果的指令，这个缓冲区被称为 *重排序缓冲区* (reorder buffer, ROB)。此外，在 IS, EXE, WR（写结果）阶段后加入提交阶段（CO）。

* IS：如果存在空的保留站和 ROB 空闲槽，则发出指令；如果操作数在寄存器或 ROB 中可用，则将其发送到保留站。更新 ROB 槽的标志以指示缓冲区正在使用中。分配给结果的 ROB 条目编号也发送到保留站，以便在结果被放置到总线时使用该编号来标记结果。
* EXE：如果所有操作数都已就位，则开始执行指令。
* WR：当结果可用时，将其放置到总线上，写入所有其他用到该结果的保留站和 ROB（不同于无 ROB 的 Tomasulo 算法，这里并不写入寄存器堆）。在无 store buffer，只有 ROB 的模型下，store 指令也需要特殊处理，将待存储的值放入 ROB 中（相当于强行延迟至少 1 周期，以避免过早造成外界可观测副作用）。
* CO：当一条指令到达 ROB 的头部并且其结果已经存在于缓冲区中时，此时处理器会将结果写入寄存器，并将该指令从 ROB 中移除。提交 store 指令类似，只是更新的是内存而不是结果寄存器。当一条具有错误预测的分支到达 ROB 的头部时，这表明预测是错误的。此时 ROB 会被清空，并在分支的正确目标地址重新开始执行。如果分支预测正确，那么该分支的执行就完成了。
--


3. *超标量*：多功能单元，单个周期内可以发射或者提交多个指令。
+
--
途径：流水线化指令发射（例如：半周期发射一条指令）；加宽发射逻辑使之支持单发射周期内发射多条指令并正确处理指令间的依赖关系。 
现代超标量处理器同时使用这两种途径。
--

4. *分支预测*：
+
--
* 1-bit 分支预测（分支预测缓冲区）；2-bit 分支预测
* 一个 stem:[(m,n)] 预测器使用最后 stem:[m] 条分支的行为，从 stem:[2^m] 个分支预测器中选择，其中每个预测器是对单条分支的 stem:[n] 位预测器。
* 锦标赛预测器：
+
[.centered]
image::/resource/arch-tournament.svg[Tournament Branch Predictor, 25rem]
* 被标记混合预测器（TAGE）：使用 PC 和 _不同长度_ 的分支历史混合后的哈希作为索引，选择不同级的分支预测表条目，并选择最长的且其 tag 相匹配的 2-bit 或 3-bit 预测器。
+
[.centered]
image::/resource/arch-tage.svg[TAGE, 40rem]

--

5. *更多高级技术*：
+
--
* 增加取指带宽：BTB（分支目标缓冲区），RAS（返回地址预测器（栈）），循环分支预测器等；集成取指单元（分支预测，指令预取，指令内存访问和缓冲）
* 推测执行的替代实现：
+
----
显式寄存器重命名：一种替代使用重排序缓冲器（ROB）的方法是显式使用一组更大的物理寄存器，并结合寄存器重命名技术。这种方法建立在 Tomasulo 算法中使用的重命名概念之上，并对其进行扩展。
在 Tomasulo 算法中，任何执行时刻，架构可见寄存器的值都存储在寄存器堆和保留站的某种组合中。
在引入推测机制后，寄存器值也可能暂时存储在 ROB 中。
无论哪种情况，如果处理器在一段时间内没有发出新指令，所有已存在的指令都会被提交，并且寄存器值将出现在寄存器文件中，这直接对应于架构可见寄存器。

在寄存器重命名方法中，使用一组扩展的物理寄存器来保存架构可见的寄存器以及临时值。
因此，这些扩展寄存器取代了大多数保留站和重排序缓冲区的功能；只需要一个队列来确保指令按顺序完成。

在指令发射过程中，重命名过程将架构寄存器的名称映射到扩展寄存器集中的物理寄存器编号，为目的地分配一个新的未使用寄存器。

WAW 和 WAR 冲突通过重命名目标寄存器得以避免；因为指令的目标寄存器在指令提交之前不会成为架构寄存器，推测错误后状态可以被自然地回滚。

重命名表是一个简单的数据结构，它提供当前对应指定架构寄存器的物理寄存器编号，这是 Tomasulo 算法中寄存器状态表执行的功能。当一条指令提交时，重命名表会被永久更新，以表明一个物理寄存器对应实际的架构寄存器，从而有效地完成对处理器状态的更新。尽管在寄存器重命名中并不总是需要 ROB，但硬件仍必须在类似队列的结构中跟踪指令，并严格按照顺序更新重命名表。

重命名方法相对于 ROB 方法的优势在于，指令提交过程略有简化，因为它只需要两个简单的操作：(1) 记录下架构寄存器编号与物理寄存器编号之间的映射不再具有推测性，(2) 释放任何正在保存架构寄存器“旧值”的物理寄存器。在具有保留站的设计中，当使用该站的指令完成执行时，该站会被释放；当对应的指令提交时，ROB 条目会被释放。

释放物理寄存器的方法：1. 检查所有功能单元队列中的源操作数，查看是否使用了该物理寄存器；检查该物理寄存器是否被指定为架构寄存器。
2. 等待直到存在一个写入相同架构寄存器的指令完成执行。（问：这里是如何直到该物理寄存器（过去）对应的架构寄存器的？）
----
+
----
有限推测：推测执行可能会触发昂贵的事件（TLB 失效、L2 缓存失效）。解决方法：推测执行时若遇到这些事件，则等待直到指令不再是推测性的。
----
--

=== 数据级并行

1. *SIMD*：单条指令同时对多个数据元素进行操作。通常是定长的，但 SVE 和 RVV 都支持变长操作。
2. *向量架构*：
+
--
* 谓词寄存器：
  向量处理器和 GPU 之间的一个区别在于它们处理条件语句的方式。向量处理器将谓词寄存器作为架构状态的一部分，并依赖编译器显式地操作掩码寄存器。相比之下，GPU 通过硬件操作内部掩码寄存器来达到相同的效果，而这些寄存器对 GPU 软件是不可见的。
* 跨步（Stride）：加载间隔固定距离的数据元素。用于多维数组。需要考虑 bank 冲突问题。
* 收集 - 分散（Gather-Scatter）：处理稀疏数组。收集指令使用额外的向量存储的索引加上基址计算出目标元素地址并加载对应元素进入向量寄存器。
  分散指令类似。
--

=== 内存层次结构

==== 缓存的基本结构

set-associative cache: 首先发现哪个 set 包含地址（block_addr % num_of_sets），
然后并行检查 set 中的所有块，查找具体哪个 tag 匹配。

写缓存的策略：

1. 写直达（Write-through）：写操作写入缓存并立即写入主内存。
2. 写回（Write-back）：写操作仅写入缓存，直到缓存块被替换时才写入主内存。

优化缓存性能的方法：

- 更大的缓存块大小：降低缺失率但提高缺失开销
- 更大的缓存：降低缺失率但提高命中时间（和功耗）
- 更高的关联度：降低冲突导致的缺失率，但提高命中时间（和功耗）
- 多级缓存
- 给予读缺失更高优先级：减小缺失开销
- 避免在查找缓存时进行地址翻译：降低命中时间（例：使用页面偏移（虚拟地址和物理地址相同的部分）来索引缓存）


==== 优化缓存

制约平均内存访问时间的三个指标：命中时间、缺失率、缺失开销。
因此，可以从以下 5 个方向优化访存性能：

1. 降低命中时间：小而简单的一级缓存；way-prediction - 降低功率消耗
2. 提高缓存贷款：流水线缓存、多 bank 缓存、非阻塞式缓存 - 对功率消耗有不同的影响
3. 降低缺失开销：关键字先行、合并写缓冲区 - 对功率影响很小
4. 降低缺失率：编译器优化
5. 使用并行性降低缺失开销和缺失率：硬件或者软件预取 - 提高功耗

具体的十个优化如下：

1. 使用小而简单的缓存。原因：关联度提高同时导致命中时间和能源消耗增加（并行比较 tag）。+
近些年某些设计使用更高关联度的原因：一些处理器至少需要 2 周期访问缓存，因此增加的命中时间无关紧要；+
其次，为了将 TLB 排除在访问缓存的关键路径上，必须在 L1 缓存上使用虚索引而非物理索引，这限制了
缓存大小必须为页大小和关联度的乘积。

2. way-prediction: 在缓存中使用额外的位来预测下次缓存访问的 way（set 里的 block）。+
在关联度较小的缓存里使用。

3. 流水线化访问和 multibank 缓存。所有处理器都在 L1 缓存上使用流水线，即使只是为了分离访问和命中检测，许多高速处理器也有三个或更多级的缓存流水线。+
可以将缓存划分为独立的 bank，每个 bank 支持独立的访问。banking 最初用于提高主存储器的性能，现在也用于现代 DRAM 芯片以及缓存中。+
一种简单的分 bank 方法（sequential interleaving）是根据 block 地址：例如，如果有四个 bank，bank 0 拥有所有地址模 4 等于 0 的块，bank 1 拥有所有地址模 4 等于 1 的块，以此类推。+

4. 非阻塞式缓存。允许发生 cache miss 时数据缓存继续为其他缓存访问提供服务。

5. 关键字先行（Critical word first）和尽早开始（Early start）：关键的观察：处理器通常只需要块中的一个字。+
两个技术分别为：关键字先行 - 首先从内存中请求缺失的单词，并在到达后立即将其发送给处理器；让处理器继续执行，同时填写块中的其余单词。+
提前重启 - 按正常顺序获取单词，但一旦请求的块单词到达，将其发送到处理器，并让处理器继续执行。

6. 合并写缓冲区。合并地址相近的写入。

7. 编译优化

8. 硬件预取

9. 编译器预取

10. 使用 HBM 拓展内存体系

==== 缓存与虚拟内存

- *VIVT (Virtual Index Virtual Tag)*：+
--
* 优点：无需经过地址翻译
* 缺点：可能出现歧义或者别名问题（切换进程前需要刷新缓存避免歧义导致的正确性问题；别名问题会产生一致性问题）
--

- *PIPT (Physical Index Physical Tag)*：+
--
* 优点：无歧义和别名问题
* 缺点：不论是否命中都需要查询 TLB 或 PTE，导致更长的延迟
--

- *VIPT (Virtual Index Physical Tag)*：+
--
* 优点：减小延迟（因为索引时不需要已翻译的物理地址）
* 缺点：由于 VI 的要求，只有当缓存每路的大小不大于页面大小时，
才能确保不会有别名问题。
--

=== GPU（老黄特辑）：

==== 老黄的 GPU 架构

* CUDA 线程：抽象的最低级的并行执行单元。

* 线程块：定义了一个组，一些线程在组内被在一起阻塞执行。

* 多线程 SIMD 处理器（流式多处理器，SM）：执行一整个线程块的处理器。一个 GPU 上可能有很多个这样的处理器。

* `+__device__+` 或 `+__global__+` 修饰的函数在 GPU 上执行，`+__host__+` 修饰的函数在 CPU 上执行。

* `+__device__+` 修饰的变量被分配在 GPU 上并可被所有（GPU 上的）多线程 SIMD 处理器访问。

* `+<<<dimGrid, dimBlock>>>+` 语法用于指定代码的维度（单位为线程块）和线程块的维度（单位为线程）。
  `+blockIdx+` 和 `+threadIdx+` 分别用于获取线程块和线程的索引。

* CUDA 编程要求：线程块内的线程可以以任意顺序独立地执行。

.GPU 术语对照表（编程抽象）
[cols="1,1,1,1",options="header"]
|===
| 描述性名称 | 最接近旧 GPU 术语 | CUDA/NVIDIA GPU 术语 | 简短解释

| Vectorizable Loop | Vectorizable Loop | Grid | 一种在 GPU 上执行的可向量化循环，由一个或多个线程块（向量化循环主体）组成，可以并行执行
| Body of Vectorized Loop | Body of a (Strip-mined) Vectorized Loop | Thread Block | 一种在多线程 SIMD 处理器上执行的向量化循环，由一个或多个 SIMD 指令线程组成，它们可以通过局部内存进行通信
| Sequence of SIMD Lane Operations | One iteration of a Scalar Loop | CUDA Thread | 对应于一个由单一 SIMD 通道执行的 SIMD 指令线程的垂直切片，结果根据掩码和谓词寄存器存储
|===

.GPU 术语对照表（物理对象）
[cols="1,1,1,1",options="header"]
|===
| 描述性名称 | 最接近旧 GPU 术语 | CUDA/NVIDIA GPU 术语 | 简短解释

| A Thread of SIMD Instructions | Thread of Vector Instructions | Warp | 一种传统线程，但仅包含 SIMD 指令，在多线程 SIMD 处理器上执行，结果根据每个元素掩码存储
| SIMD Instruction | Vector Instruction | PTX Instruction | 一种跨 SIMD 通道执行的单一 SIMD 指令
|===

.GPU 术语对照表（计算硬件）
[cols="1,1,1,1",options="header"]
|===
| 描述性名称 | 最接近旧 GPU 术语 | CUDA/NVIDIA GPU 术语 | 简短解释

| Multithreaded SIMD Processor | (Multithreaded) Vector Processor | Streaming Multiprocessor | 一种多线程 SIMD 处理器，执行独立的 SIMD 指令线程，与其他 SIMD 处理器无关
| Thread Block | Scalar Processor | Giga Thread Engine | 将多个线程块（向量化循环主体）分配给多线程 SIMD 处理器
| SIMD Thread Scheduler | Thread Scheduler in a Multithreaded CPU | Warp Scheduler | 一种硬件单元，负责调度和分发就绪的 SIMD 指令线程；包括一个记分板来跟踪 SIMD 线程执行
| SIMD Lane | Vector Lane | Thread Processor | 一种 SIMD 通道，在单一元素上执行线程中的操作，结果根据掩码存储
|===

.GPU 术语对照表（内存硬件）
[cols="1,1,1,1",options="header"]
|===
| 描述性名称 | 最接近旧 GPU 术语 | CUDA/NVIDIA GPU 术语 | 简短解释

| GPU Memory | Main Memory | Global Memory | 所有多线程 SIMD 处理器可访问的 DRAM 内存
| Private Memory | Stack or Thread Local Storage (OS) | Local Memory | 每个 SIMD 通道专属的 DRAM 内存部分
| Local Memory | Local Memory | Shared Memory | 专属于一个多线程 SIMD 处理器的高速本地 SRAM，其他 SIMD 处理器无法访问
| SIMD Lane Registers | Vector Lane Registers | Thread Processor Registers | 分配给单个 SIMD 通道的寄存器，覆盖整个线程块（向量化循环主体）
|===

==== PTX 指令集

硬件指令集上的一层额外抽象。

指令格式：`+opcode.type d, a, b, c;+`

.PTX 数据类型
[cols="1,1"]
|===
| 无类型 | `.b8`, `.b16`, `.b32`, `.b64`
| 无符号整数 | `.u8`, `.u16`, `.u32`, `.u64`
| 有符号整数 | `.s8`, `.s16`, `.s32`, `.s64`
| 浮点数 | `.f16`, `.f32`, `.f64`
| 谓词 | `+.pred+`
|===

详见 https://docs.nvidia.com/cuda/parallel-thread-execution/index.html?highlight=type#fundamental-types[PTX 基础数据类型]。

一些指令：

* 控制流：`call`，`return`
* 屏障（线程块内同步）：`bar.sync`

所有指令都可以被 1 位的谓词修饰。`R0`, `R1`, ... 表示 32 位寄存器，`RD0`, `RD1`, ... 表示 64 位寄存器。

*GPU 上的条件分支*：

显式谓词寄存器、内部掩码、分支同步栈、指令标记等手段。

在 PTX 汇编层面，有 `branch`，`call`，`return`，`exit` 等指令，外加用户指定的谓词修饰。

在 GPU 硬件层面，有 `branch`，`jump`，`jump indexed`，`call`，`call indexed`，`return`，`exit` 等指令，
并且有特殊指令管理来处理分支同步栈。GPU 硬件为每个 SIMD 线程提供自己的栈；
栈条目包含一个标识符令牌、目标指令地址和目标线程活动掩码。
有一些 GPU 专用指令，用于将栈条目压栈到 SIMD 线程中，
以及专用指令和指令标记，用于弹出栈条目或回退到指定的栈条目，
并根据目标指令地址和目标线程活动掩码进行分支。
GPU 分支指令通过分支同步栈在某些通道分支到目标地址时压入一个栈条目，而其他通道则继续执行。
NVIDIA 称这种情况为分支发散。
这种混合也用于当 SIMD 通道执行同步标记或汇聚时，
此时会弹出一个栈条目，并根据栈条目中的线程活动掩码分支到栈条目地址。
（具体执行方式，参考 fine-grained SIMD）。


== SyOC（一个学习用编译器项目）

- *手写的递归下降解析器*
- *SSA IR 设计*：所有值都具有一个相同的基类，其中包含有一个 kind tag，父指针，use chain，还有一个 id。
  其中，kind tag 用于区分值的类型，父指针用于跟踪所属关系，use chain 用于表示值的依赖关系，id 用于表示值的唯一编号。
  use chain 是一个 edge 的双端链表，方便插入和删除，其中 edge 包含了源和目标。
  修改指令的操作数时自动更新对应的边和链表。支持了 replaceAllUsesWith 操作。
- *Transformer 设计*：利用 C++ 泛型构造 Pass 然后执行。
- *优化 Pass*：CFG 化简（合并基本块、移除没有前驱的基本块），
  Alloca 相关优化（清理无 user 的加载；只定义一次（store 1 次）的情况下则替换掉所有受支配的块的 load 指令），
  Mem2Reg（构建 SSA 形式 IR）；保守的 DCE（删除没有用户的指令）；常量传播。


== 寄存器分配

*弦图着色*：无向图是弦图，如果图中每个长度为 4 或更长的环都有弦。
图中的节点 stem:[v] 是单形（simplicial）的，如果它的邻域形成一个团 (clique)，
也就是说，stem:[v] 的所有邻居彼此相连，因此需要不同的颜色。
如果图中的节点 stem:[v_1, \dots , v_n] 的一个排列使得每个节点 stem:[v_i] 在子图 stem:[v_1, \dots , v_i] 
中都是单形的，那么这个排列称为单形消除排列。
一个图有单形消除排列当且仅当它是弦图。
当这样的排列存在时，按该排列贪心着色即可得到一个最优图着色。

// *迭代寄存器合并*：
// *线性扫描*：


== 垃圾回收

=== 标记 - 清扫

- 分配：尝试分配，不成功则开始一轮清扫，再试不成功则失败。
- 标记：初始化工作列表（栈或其他实现），从根节点开始，标记所有可达对象。
- 清扫：遍历堆，查看对象并标记未被回收的对象。

优化：

1. 使用 Bitmap marking。
2. Lazy sweeping（标记阶段完成后不进行清扫，而是在分配时清扫）。

=== 标记 - 压缩

==== 2-Finger 算法

使用两个指针，一个指向当前位于堆最前部的空闲区开始，另一个指向当前处理的对象。
空闲指针从堆开始向堆末尾移动，而处理指针从堆末尾向堆开始移动。
当两指针相遇时，则工作完成。

如何更新引用？
检测指向的内容是否位于压缩完后的堆区上界之外。如果是，则从指向的旧地址中加载之前存储的转发指针，
并更新对应的引用。

==== Lisp 2 算法

压缩阶段遍历三趟堆：

1. 计算对象被移动到的目标地址，并在对象的转发地址中存储该地址。
+
--
[source]
----
computeLocations(start, end, toRegion):
  scan ← start
  free ← toRegion
  while scan < end
    if isMarked(scan)
      forwardingAddress(scan) ← free
      free ← align(free + size(scan))
    scan ← nextObject(scan)
----
--

2. 使用对象里存储的转发地址更新引用。
+
--
[source]
----
updateReferences(start, end):
  for each fld in Roots /* update roots */
    ref ← *fld
    if ref ̸= null
      *fld ← forwardingAddress(ref)
  scan ← start /* update fields */
  while scan < end
    if isMarked(scan)
      for each fld in Pointers(scan)
        if *fld ̸= null
          *fld ← forwardingAddress(*fld)
    scan ← nextObject(scan)
----
--

3. 移动存活对象。
+
--
[source]
----
relocate(start, end):
  scan ← start
  while scan < end
    if isMarked(scan)
      dest ← forwardingAddress(scan)
      move(scan, dest)
      unsetMarked(dest)
    scan ← nextObject(scan)
----
--

=== 复制垃圾回收器

==== 半空间复制

分配：

[source]
----
atomic allocate(size):
  result ← free
  newfree ← result + size
  if newfree > top
    return null /* signal ‘Memory exhausted’ */
  free ← newfree
  return result
----

Cheney's 算法：

特点：无需额外空间（不过需要至少一个字 + 一个状态位来存储转发指针）。

使用新的 to space 空间作为一个 FIFO 队列，来存储遍历对象 fields 时发现的子对象。
工作流程如下：

- 翻转 to space 和 from space 的角色。
- 设置 scan 和 free 指针为 to space 的开始。
- 扫描 roots 指向的对象复制到 free 指向的空间，对应地递增 free 指针。
- 开始扫描 scan 指向的对象，类似地，将所有子对象复制到 free 并且递增 free 指针。处理完成后，递增 scan 指针到下一个对象。
- 当复制时，需要注意的是，我们通过检查 from space 里的旧对象的 status bit 和 forward pointer 来判断该对象是否已经被复制过；如果是的话，
  则直接使用对应的 forward pointer 来更新，而不进行额外的复制。

Cheney 算法经常被称作 BFS 算法。

=== 垃圾回收器的吞吐指标

1. 吞吐量
2. 延迟：回收器中断正常程序执行的时间

=== 分配

各种 -fit 算法 + 根据大小分类并使用多个分配器的 segregated-list 算法。

=== 分代

*弱分代假设*：大部分对象在年轻的时候便很快死亡。

*强分代假设*：即使对于不是新创建的对象，较年轻的对象的存活率也会低于较老的对象。（无充分证据表明成立）

==== 记忆集

记录从堆的某个区域到其他区域的指针的来源。

=== 运行时接口

==== 值的指针寻找

- 保守式
- 使用标记值；或者使用 big bag of pages 方式给每个块关联一个 tag

==== 对象内的指针寻找

- 使用一张表记录指针位置（利用 object 记录的类型元数据等捎带）
- 使用 bitmap 辅助
- 分区为指针区和非指针区（子类怎么办？双向扩增）

==== 栈和寄存器中的指针寻找

三个问题：

1. 找到帧
2. 找到帧内的指针
3. 参数传递、返回值等在不同调用约定下的处理

*堆栈映射*：

- bitmap
- 分区

问题：泛型函数

*优化堆栈扫描*：堆栈标记和栈屏障

*在寄存器中查找指针*：好复杂，TODO

*处理内部指针（指向对象中间的指针）*：big bags of pages；其余情况则应禁用，因为得不偿失。

==== 堆栈屏障

可以逐级扫描堆栈，同时也可以使用堆栈屏障进行并发扫描。+
其思路是在线程尝试从其堆栈中返回（或抛出）超过给定帧时将其引导到堆栈扫描代码。+
假设我们在帧 F 中放置了一个屏障。+
然后我们可以异步处理 F 的调用者、其调用者等等，+
且可以保证正在运行的线程不会在我们扫描时从下面截断堆栈。

关键：劫持返回地址

==== GC 安全点

避免任意时刻进行垃圾回收带来的成本（例如，多份堆栈映射）或错误（拆分的原子步骤）。

最小安全点：

- 分配时
- 每次调用具有分配的函数时

更多可行点：

- 后边
- 进入函数和退出函数时

==== 写屏障和读屏障

*写屏障的精度*：在记忆集中更精确地记录有趣的指针意味着收集者找到指针的工作量减少，但突变者过滤和记录它的工作量增加。

- 精确性
- 粒度（例如：卡表）
- 是否允许重复

*卡表*：卡片表（卡片标记）方案将堆在概念上划分为固定大小、连续的区域，称为卡片。卡片通常很小，介于 128 到 512 字节之间。+
每当写入指针时，写入屏障会设置包含指针（例如，参见图 11.3）的卡片对应的卡片表中的条目的脏位。

==== 虚拟内存

*禁止访问页面的用途*：

- 在 GC 安全点停止 mutator 进程
- 检测解引用空指针
- 作为保护页用于处理各种慢速路径

=== 并行与并发回收

分类：

[.centered]
image::/resource/gc-stw.svg["STW GC 的分类", 40rem]

[.centered]
image::/resource/gc-concurrent.svg["并发 GC 的分类", 40rem]

==== 并行标记

并行标记包括三个活动：从工作列表中获取一个要处理的对象，测试和设置一个或多个标记，
以及通过将对象的子对象添加到工作列表中生成进一步的标记工作。
如果工作列表是线程局部且非空的，则不需要同步来获取要跟踪的对象。
否则，线程必须原子性地获取工作，
要么从其他线程的工作列表中获取，要么从某个全局列表中获取。
原子性主要是为了维护获取工作所用的列表的完整性。
在非移动收集器中，对一个对象进行多次标记或将其子对象添加到多个工作列表中只会影响性能，而不会影响正确性。

==== 并行复制、压缩、清扫

TODO

==== 并发

当突变器与收集器同时运行并在灰色波前修改灰色对象（其字段仍需扫描）或白色对象（尚未到达），
由于收集器最终仍会访问这些对象（如果它们仍然可访问），因此正确性得以保证。
如果突变器修改波后对象，也就是黑色对象（其字段已被扫描）——也没有问题，
只要它只插入或删除指向黑色或灰色对象的指针（收集器已决定它们是可访问的）。
然而，其他指针更新可能导致突变器和收集器对活动对象集合的看法不一致，从而导致活动对象被错误地释放。

丢失的对象问题

*弱三色不变量*：所有被黑色对象指向的白色对象都是灰色受保护的（也就是说，可以从某个灰色对象到达，无论是直接还是通过白色对象的链）。

*强三色不变量*：黑色对象不能指向白色对象。


LuaJIT：当标记完成（黑色对象）的字段被指向未标记（白色）对象时，如何维护三色不变量？

- 将黑色对象变为未完全标记（灰色）对象。造成标记前沿的“撤退”。适合容器类型对象，因为接下来还可能会有一系列的元素存储。
- 将白色对象变为未完全标记（灰色）对象。造成标记前沿的“扩张”。适合非容器类型对象。

SATB：当灰色对象不再指向白色对象时，记录该白色对象。

=== 常见垃圾回收器

*G1*：分代，卡表记忆集，压缩

*ZGC*：并发，压缩，读屏障，写屏障（分代模式）


== 案例学习

=== Google V8

==== 去优化

1. 首先，我们保存当前的程序状态。我们通过从优化代码调用运行时来实现这一点。然后，Deoptimizer 将当前程序状态序列化到一个内部数据结构中，即 FrameDescription。这包括读取 CPU 寄存器并检查要去优化的函数的栈帧。

2. 接下来，我们将转换此状态，使其适应未优化代码，也就是说，将值放置在 Liftoff 生成的代码在去优化点所期望的正确寄存器和栈槽中。例如，TurboFan 代码放在寄存器中的值现在可能最终存放在栈槽中。基线代码的栈布局和期望（如果你愿意，可以称为去优化点的“调用约定”）是从 Liftoff 在编译期间生成的元数据中读取的。 

3. 最后，我们用相应的未优化栈帧替换优化后的栈帧，并跳转到基线代码的中间位置，该位置对应于触发去优化的优化代码中的点。

==== Sea of Nodes

不表示基本块，而只表示指令之间的真实依赖关系。多种效果边。

==== V8 放弃 SoN 的各种原因

1. 手动/目视检查和理解 SoN 图很困难。
2. 效果链上的节点过多或具有控制输入。（例子：JS 很多宏操作会被 lower 到一系列更底层、有效果的指令上，并形成效果依赖）
3. 内存效果不容易进行浮动。（例子：。当分支的两个目标都有副作用时，效果链会在控制链分裂和合并的地方完全相同地分裂和合并。有副作用的节点通常被限制安排在两个控制节点之间，也就是在一个基本块内。在这个基本块内，效果链会约束有副作用的节点保持与源代码中相同的顺序）
4. 手动管理效果链和控制链很困难。
5. 难以找到合适的顺序遍历图。
6. 图表示法容易导致缓存缺失。
7. 难以使用控制流约束数据流（例子：如果测试了一个数满足特定条件，
那么在 CFG 里可以自然的假设在分支成立的基本块中这个条件成立并进行对应优化。但在 SoN 里，
由于计算是可以浮动的，并不能利用该性质进行优化，除非显式加入控制依赖，但这相当于重建了 CFG）


== Calocom（一个课程项目）

新意：

- *代数数据类型*
- *高阶函数*
- *嵌套的模式匹配支持*
- *中间 IR* 具有类三地址码的结构，特殊之处在于每个函数存在所谓“捕获变量”，可以作为正常值一样使用。
- *后端* 会在入口点处去从闭包中对应偏移量处的自由变量到关联的“捕获变量”中去。
- *名称修饰* 模仿 Swift 和 C++ 形成了一套自己的命名风格，编码内置类型、用户定义的 ADT、数据等
  总结：显式编码标识符长度；C 前缀类型；编码路径；区分多态和单态函数
- *运行时* 使用 unsafe Rust 实现，常见的数组、字符串操作函数等

== Apple-uArch-benchmark

1. 测量乱序窗口大小：使用不同数量 `nop` 类指令填充缓冲区。
2. 测量重命名窗口大小：使用不同数量的 `mov x5, #0` 类指令填充缓冲区。
3. 测量加载缓冲区大小：使用不同数量的 `ldr x5, [x2]` 类指令填充缓冲区。
4. 测量存储缓冲区大小：使用不同数量的 `str x5, [x2, #8]` 类指令填充缓冲区。
5. 测量标量寄存器堆大小：使用不同数量的 `add x5, x11, x11` 类指令填充缓冲区。
6. 测量向量寄存器堆大小：使用不同数量的 `add v0.16b, v1.16b, v2.16b` 类指令填充缓冲区。
7. 测量调度器大小：使用不同数量的 `add x5, x0, x1` 类指令填充缓冲区。
